{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (1.24.3)\n",
      "Requirement already satisfied: matplotlib in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: scikit-learn in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: tensorflow in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (2.13.0)\n",
      "Requirement already satisfied: scikit-image in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (0.24.0)\n",
      "Requirement already satisfied: torch in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (1.7.1)\n",
      "Requirement already satisfied: torchvision in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (0.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (4.25.6)\n",
      "Requirement already satisfied: setuptools in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: imageio>=2.33 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from scikit-image) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from scikit-image) (2024.8.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (8.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/w2sg-arnav/anaconda3/envs/tf_gpu_env/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python numpy matplotlib scikit-learn tensorflow scikit-image torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 17:51:49.735271: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-03 17:51:49.736908: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-03 17:51:49.768956: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-03 17:51:49.769648: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-03 17:51:50.276549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skimage.segmentation import slic\n",
    "from skimage.color import label2rgb, rgb2lab\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2: Configuration and Constants\n",
    "This cell defines constants and paths, making it easy to adjust parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/w2sg-arnav/msusir/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection\"\n",
    "ORIGINAL_DIR = os.path.join(DATASET_ROOT, \"Cotton Leaf Disease Detection Dataset\", \"Original Dataset\")\n",
    "AUGMENTED_DIR = os.path.join(DATASET_ROOT, \"Cotton Leaf Disease Detection Dataset\", \"Augmented Dataset\")\n",
    "\n",
    "IMAGE_SIZE = (224, 224)  # Adjust as needed for your models (e.g., 384x384 for ViT)\n",
    "CLASSES = [\n",
    "    \"Bacterial Blight\",\n",
    "    \"Curl Virus\",\n",
    "    \"Healthy Leaf\",\n",
    "    \"Herbicide Growth Damage\",\n",
    "    \"Leaf Hopper Jassids\",\n",
    "    \"Leaf Redding\",\n",
    "    \"Leaf Variegation\",\n",
    "]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "BATCH_SIZE = 32  # Adjust based on your GPU memory\n",
    "EPOCHS = 30      # Adjust as needed\n",
    "LEARNING_RATE = 1e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: Data Loading Functions\n",
    "\n",
    "Functions to load and organize the image data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, use_augmentation=False):\n",
    "    \"\"\"Loads images and labels from a directory structure.\"\"\"\n",
    "    image_files = []\n",
    "    labels = []\n",
    "\n",
    "    for class_name in CLASSES:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                image_files.append(os.path.join(class_dir, filename))\n",
    "                labels.append(class_name)  # Store class name as string\n",
    "\n",
    "    return image_files, labels\n",
    "\n",
    "\n",
    "def create_tf_dataset(image_files, labels, preprocess_fn, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Creates a TensorFlow dataset for efficient data loading.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_files, labels))\n",
    "\n",
    "    def _load_and_preprocess(image_path, label):\n",
    "        image_string = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_image(image_string, channels=3, expand_animations=False) # Handle potential errors\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        [image, ] = tf.py_function(preprocess_fn, [image_path], [tf.float32])\n",
    "        image.set_shape([None, None, 3])\n",
    "        return image, label\n",
    "\n",
    "    dataset = dataset.map(_load_and_preprocess)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6: Preprocessing Functions\n",
    "\n",
    "These functions perform image segmentation, noise reduction, and orientation normalization.  These are *examples* and should be refined/replaced with more robust methods as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_leaf(image):\n",
    "    \"\"\"Segments the leaf from the background using SLIC.\"\"\"\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2Lab)\n",
    "    segments = slic(image_lab, n_segments=100, compactness=10, sigma=1, start_label=1)\n",
    "    largest_segment_label = np.argmax(np.bincount(segments.ravel())[1:]) + 1\n",
    "    leaf_mask = (segments == largest_segment_label).astype(np.uint8)\n",
    "    segmented_image = cv2.bitwise_and(image, image, mask=leaf_mask)\n",
    "    return segmented_image, leaf_mask\n",
    "\n",
    "def reduce_noise(image):\n",
    "    \"\"\"Applies Non-Local Means Denoising.\"\"\"\n",
    "    denoised_image = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
    "    return denoised_image\n",
    "\n",
    "def normalize_orientation(image, mask):\n",
    "    \"\"\"Basic orientation normalization.\"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        if len(largest_contour) >= 5:\n",
    "            ellipse = cv2.fitEllipse(largest_contour)\n",
    "            angle = ellipse[2]\n",
    "            (h, w) = image.shape[:2]\n",
    "            center = (w // 2, h // 2)\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    "            rotated_mask = cv2.warpAffine(mask, rotation_matrix, (w, h))\n",
    "            return rotated_image, rotated_mask\n",
    "    return image, mask\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads, preprocesses, and returns a single image.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    segmented_image, leaf_mask = segment_leaf(image)\n",
    "    denoised_image = reduce_noise(segmented_image)\n",
    "    normalized_image, _ = normalize_orientation(denoised_image, leaf_mask)\n",
    "    resized_image = cv2.resize(normalized_image, IMAGE_SIZE)\n",
    "    final_image = resized_image.astype(np.float32) / 255.0\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 8: Data Loading and Splitting\n",
    "\n",
    "This cell loads the data, splits it into training, validation, and test sets, and converts labels to the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/w2sg-arnav/msusir/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Cotton Leaf Disease Detection Dataset/Original Dataset/Bacterial Blight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image_files, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mORIGINAL_DIR\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Or AUGMENTED_DIR\u001b[39;00m\n\u001b[1;32m      3\u001b[0m train_files, test_files, train_labels, test_labels \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      4\u001b[0m     image_files, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mlabels\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m train_files, val_files, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      7\u001b[0m     train_files, train_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mtrain_labels\n\u001b[1;32m      8\u001b[0m )\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data_dir, use_augmentation)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m CLASSES:\n\u001b[1;32m      7\u001b[0m     class_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, class_name)\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     10\u001b[0m             image_files\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_dir, filename))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/w2sg-arnav/msusir/SAR-CLD-2024 A Comprehensive Dataset for Cotton Leaf Disease Detection/Cotton Leaf Disease Detection Dataset/Original Dataset/Bacterial Blight'"
     ]
    }
   ],
   "source": [
    "image_files, labels = load_data(ORIGINAL_DIR)  # Or AUGMENTED_DIR\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "    image_files, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    train_files, train_labels, test_size=0.25, random_state=42, stratify=train_labels\n",
    ")\n",
    "\n",
    "# Convert labels to numerical format\n",
    "label_to_index = {label: i for i, label in enumerate(CLASSES)}\n",
    "train_labels_int = np.array([label_to_index[label] for label in train_labels])\n",
    "val_labels_int = np.array([label_to_index[label] for label in val_labels])\n",
    "test_labels_int = np.array([label_to_index[label] for label in test_labels])\n",
    "\n",
    "# One-hot encode\n",
    "train_labels_onehot = to_categorical(train_labels_int, num_classes=NUM_CLASSES)\n",
    "val_labels_onehot = to_categorical(val_labels_int, num_classes=NUM_CLASSES)\n",
    "test_labels_onehot = to_categorical(test_labels_int, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_ds = create_tf_dataset(train_files, train_labels_onehot, preprocess_image)\n",
    "val_ds = create_tf_dataset(val_files, val_labels_onehot, preprocess_image)\n",
    "test_ds = create_tf_dataset(test_files, test_labels_onehot, preprocess_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 10:  Data Visualization (Optional)\n",
    "\n",
    "This cell displays a few preprocessed images to visually check the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Visualize some preprocessed images\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(min(5, len(train_files))):  # Display up to 5 images\n",
    "    image = preprocess_image(train_files[i])  # Load and preprocess\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(train_labels[i])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 12: Model Definition (ViT and CNN Ensemble)\n",
    "\n",
    "This cell defines the Vision Transformer (ViT) and CNN (EfficientNetV2B0) models and creates an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">85,651,975</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,238,231</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │ \u001b[38;5;34m85,651,975\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │  \u001b[38;5;34m7,238,231\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ functional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ functional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │        \u001b[38;5;34m105\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,890,311</span> (354.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m92,890,311\u001b[0m (354.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,829,703</span> (354.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m92,829,703\u001b[0m (354.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,608</span> (236.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m60,608\u001b[0m (236.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 13: Model Definition\n",
    "def create_vit_model(input_shape=IMAGE_SIZE + (3,), num_classes=NUM_CLASSES):\n",
    "    vit_model = tf.keras.applications.vit.ViT(\n",
    "        input_shape=input_shape,\n",
    "        num_classes=num_classes,\n",
    "        classifier_activation='softmax',\n",
    "        include_top=True,\n",
    "        include_preprocessing=False # Important: We do our own preprocessing\n",
    "    )\n",
    "    return vit_model\n",
    "\n",
    "\n",
    "def create_cnn_model(input_shape=IMAGE_SIZE + (3,), num_classes=NUM_CLASSES):\n",
    "    base_model = EfficientNetV2B0(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Add dropout for regularization\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def create_ensemble(vit_model, cnn_model, input_shape=IMAGE_SIZE+(3,)):\n",
    "    vit_input = Input(shape=input_shape)\n",
    "    cnn_input = Input(shape=input_shape)\n",
    "\n",
    "    vit_output = vit_model(vit_input)\n",
    "    cnn_output = cnn_model(cnn_input)\n",
    "\n",
    "    # Simple Averaging Ensemble\n",
    "    merged = concatenate([vit_output, cnn_output])\n",
    "    # Optionally add a dense layer after concatenation for further processing\n",
    "    # merged = Dense(512, activation='relu')(merged)\n",
    "    output = Dense(NUM_CLASSES, activation='softmax')(merged) # Combine predictions\n",
    "\n",
    "    ensemble_model = Model(inputs=[vit_input, cnn_input], outputs=output)\n",
    "    return ensemble_model\n",
    "\n",
    "\n",
    "# Create the individual models\n",
    "vit_model = create_vit_model()\n",
    "cnn_model = create_cnn_model()\n",
    "# Create the ensemble model\n",
    "ensemble_model = create_ensemble(vit_model, cnn_model)\n",
    "\n",
    "ensemble_model.compile(optimizer=AdamW(learning_rate=LEARNING_RATE),\n",
    "                      loss=CategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "ensemble_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Backbone', 'DilatedResNet', 'EfficientNet', 'List', 'MobileDet', 'MobileNet', 'Optional', 'ResNet', 'RevNet', 'SpineNet', 'SpineNetMobile', 'Transformer', 'Tuple', 'VisionTransformer', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'dataclasses', 'hyperparams']\n"
     ]
    }
   ],
   "source": [
    "import official.vision.configs.backbones as backbones\n",
    "print(dir(backbones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 14:  Training Callbacks\n",
    "\n",
    "This cell sets up callbacks for model checkpointing, early stopping, and learning rate scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 16:01:35.507821: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.508075: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "\t [[{{node EagerPyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n",
      "2025-03-02 16:01:35.508697: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.555460: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.569835: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/li"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) UNKNOWN:  error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n\nTraceback (most recent call last):\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n    image = cv2.imread(image_path)\n            ^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n\nTraceback (most recent call last):\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n    image = cv2.imread(image_path)\n            ^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_504345]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 62\u001b[0m\n\u001b[1;32m     55\u001b[0m ensemble_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     56\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[1;32m     57\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Use 'categorical_crossentropy' for one-hot encoded labels\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# --- Train the Model ---\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mensemble_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) UNKNOWN:  error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n\nTraceback (most recent call last):\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n    image = cv2.imread(image_path)\n            ^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n\nTraceback (most recent call last):\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n    image = cv2.imread(image_path)\n            ^^^^^^^^^^^^^^^^^^^^^^\n\ncv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_504345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.570963: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.571872: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.572484: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.572975: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.573346: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.574321: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.575457: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.576601: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/li"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.577952: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.579820: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.580851: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 16:01:35.581387: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    return func(device, token, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 145, in __call__\n",
      "    outputs = self._call(device, args)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 152, in _call\n",
      "    ret = self._func(*args)\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/w2sg-arnav/.local/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/tmp/ipykernel_28622/4293546220.py\", line 35, in preprocess_image\n",
      "    image = cv2.imread(image_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "cv2.error: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'imread'\n",
      "> Overload resolution failed:\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      ">  - Expected 'filename' to be a str or path-like object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Training Callbacks\n",
    "checkpoint_filepath = 'best_ensemble_model.h5'  # Save the best model\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  # Stop if validation loss doesn't improve for 10 epochs\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "callbacks = [model_checkpoint_callback, early_stopping_callback, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 16: Training Loop\n",
    "\n",
    "This cell trains the ensemble model.  Since it's an ensemble, we need to provide *both* inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 7), output.shape=(None, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m ensemble_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[1;32m      7\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Use 'sparse_categorical_crossentropy' for integer labels\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Then fit\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mensemble_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:725\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    723\u001b[0m     )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    726\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `output` must have rank (ndim) `target.ndim - 1`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[0;31mValueError\u001b[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 7), output.shape=(None, 7)"
     ]
    }
   ],
   "source": [
    "# Cell 17: Training\n",
    "\n",
    "# Prepare data for the ensemble (both models get the same preprocessed images)\n",
    "def prepare_ensemble_data(dataset):\n",
    "    for images, labels in dataset:\n",
    "        yield [images, images], labels  # Input for both models, and the labels\n",
    "\n",
    "train_ds_ensemble = train_ds.map(lambda x, y: ([x, x], y))\n",
    "val_ds_ensemble = val_ds.map(lambda x, y: ([x, x], y))\n",
    "test_ds_ensemble = test_ds.map(lambda x, y: ([x, x], y))\n",
    "\n",
    "\n",
    "history = ensemble_model.fit(\n",
    "    train_ds_ensemble,\n",
    "    validation_data=val_ds_ensemble,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1  # Show progress\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 18:  Evaluation\n",
    "\n",
    "This cell evaluates the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Evaluation\n",
    "\n",
    "loss, accuracy = ensemble_model.evaluate(test_ds_ensemble, verbose=1)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# --- Further Evaluation (ROC, AUC, Specificity, Sensitivity) ---\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred_probs = ensemble_model.predict(test_ds_ensemble)  # Probabilities\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Predicted classes\n",
    "y_true = test_labels_int  # True integer labels\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n",
    "\n",
    "# --- Classification Report (Precision, Recall, F1-score) ---\n",
    "class_report = classification_report(y_true, y_pred, target_names=CLASSES)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "# --- ROC Curves and AUC ---\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_labels_onehot[:, i], y_pred_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(NUM_CLASSES):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {CLASSES[i]} (area = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Display Training History ---\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 20:  Grad-CAM Visualization (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: Grad-CAM\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    \"\"\"Generates a Grad-CAM heatmap for a given image and model.\"\"\"\n",
    "\n",
    "    # Create a model that maps the input image to the activations of the last conv layer\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Compute the gradient of the top predicted class for the input image\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron with regard to the output feature map\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # Pool the gradients over all the axes, leaving out the channel dimension\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Multiply each channel in the feature map by \"how important this channel is\"\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # Average the channels of the feature map to obtain the heatmap\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # Normalize the heatmap\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Choose an image for visualization\n",
    "img_path = test_files[0]  # Example: Use the first test image\n",
    "img_array = preprocess_image(img_path)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "\n",
    "# --- Grad-CAM for the CNN model ---\n",
    "last_conv_layer_name_cnn = \"top_activation\" # Find the name of the last conv layer in your CNN\n",
    "\n",
    "heatmap_cnn = make_gradcam_heatmap(img_array, cnn_model, last_conv_layer_name_cnn)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap_cnn)\n",
    "plt.title(\"Grad-CAM Heatmap (CNN)\")\n",
    "plt.show()\n",
    "\n",
    "# --- Grad-CAM for ViT ---\n",
    "#   ViT's structure is different. You need to access the attention weights.\n",
    "#   This requires a different approach, and there isn't a single \"last convolutional layer.\"\n",
    "#   The following is a *simplified conceptual example* and needs adaptation\n",
    "#   for a specific ViT implementation.  It's often more complex than for CNNs.\n",
    "\n",
    "def vit_gradcam_simplified(img_array, model, layer_name=\"encoder_layer_11\"):\n",
    "    \"\"\"Simplified Grad-CAM for ViT (Conceptual Example).\"\"\"\n",
    "\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs, preds = grad_model(img_array)\n",
    "        pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, outputs)\n",
    "    #This part is different to a CNN, you need to adapt based on the way ViT is implemented\n",
    "    weights = tf.reduce_mean(grads, axis=(1)) # Average across the sequence length\n",
    "    heatmap = tf.reduce_sum(weights * outputs, axis=-1) # Linear combination\n",
    "    heatmap = tf.squeeze(heatmap, axis=0)\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "# Find an appropriate layer name within your ViT model.\n",
    "# You might inspect the model summary and choose a layer within the transformer encoder.\n",
    "last_conv_layer_name_vit = 'transformer_block_11'  # Example layer name -  CHANGE THIS!\n",
    "\n",
    "if last_conv_layer_name_vit:\n",
    "    try:\n",
    "        heatmap_vit = vit_gradcam_simplified(img_array, vit_model, last_conv_layer_name_vit)\n",
    "        plt.matshow(heatmap_vit)\n",
    "        plt.title(\"Grad-CAM Heatmap (ViT - Simplified)\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "      print(\"Grad-CAM failed for ViT: \", e)\n",
    "else:\n",
    "    print(\"Grad-CAM for ViT skipped - no suitable layer name provided.\")\n",
    "\n",
    "\n",
    "# --- Overlay Heatmap on Original Image (for both CNN and ViT, if available) ---\n",
    "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
    "    \"\"\"Overlays the Grad-CAM heatmap on the original image.\"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap * alpha + img\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Display for CNN\n",
    "display_gradcam(img_path, heatmap_cnn)\n",
    "plt.title(\"Grad-CAM Overlay (CNN)\")\n",
    "plt.show()\n",
    "\n",
    "# Display for ViT (if heatmap was successfully generated)\n",
    "if 'heatmap_vit' in locals():  # Check if heatmap_vit exists\n",
    "    display_gradcam(img_path, heatmap_vit)\n",
    "    plt.title(\"Grad-CAM Overlay (ViT)\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
